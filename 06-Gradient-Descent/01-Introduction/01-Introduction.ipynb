{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 梯度下降法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 不是一个机器学习算法\n",
    "- 是一种基于搜索的最优化方法\n",
    "- 作用：最小化一个损失函数\n",
    "- 梯度上升法：最大话一个效用函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导数代表方向，对应J增大的方向"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要想使J减小，需要向J减小的方向移动，步长为$\\eta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    -\\eta\\frac{dJ}{d\\theta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\eta$为学习率(learning rate)\n",
    "- $\\eta$的取值影响获得最优解的速度\n",
    "- $\\eta$的取值不合适，甚至的不到最有解\n",
    "- $\\eta$是梯度下降法的一个超参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\eta$太小，会减慢收敛学习速度\n",
    "- $\\eta$太大，甚至不收敛\n",
    "- 并不是所有函数都有唯一的极值点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解决方案:\n",
    "- 多次运行，随机化初识点\n",
    "- 梯度下降法的初识点也是一个超参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线性回归中使用梯度下降法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目标：使$\\sum_{i=1}^m(y^{(i)} - \\hat{y}^{(i)})^2$尽可能小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归法的损失函数具有唯一的最优解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
