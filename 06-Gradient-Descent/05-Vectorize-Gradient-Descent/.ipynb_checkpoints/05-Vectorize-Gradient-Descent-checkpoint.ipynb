{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 梯度下降法的向量化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\nabla J(\\theta) = = \\frac{2}{m} \\cdot \\left(\n",
    "\\begin{matrix}\n",
    "\\sum_{i=1}^m(X_b^{(i)}\\theta - y^{(i)}) \\\\\n",
    "\\sum_{i=1}^m(X_b^{(i)}\\theta - y^{(i)}) * X_1^{(i)} \\\\\n",
    "\\sum_{i=1}^m(X_b^{(i)}\\theta - y^{(i)}) * X_2^{(i)} \\\\\n",
    "... \\\\\n",
    "\\sum_{i=1}^m(X_b^{(i)}\\theta - y^{(i)}) * X_n^{(i)}\n",
    "\\end{matrix}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\nabla J(\\theta) = = \\frac{2}{m} \\cdot \\left(\n",
    "\\begin{matrix}\n",
    "\\sum_{i=1}^m(X_b^{(i)}\\theta - y^{(i)}) * X_0^{(i)} \\\\\n",
    "\\sum_{i=1}^m(X_b^{(i)}\\theta - y^{(i)}) * X_1^{(i)} \\\\\n",
    "\\sum_{i=1}^m(X_b^{(i)}\\theta - y^{(i)}) * X_2^{(i)} \\\\\n",
    "... \\\\\n",
    "\\sum_{i=1}^m(X_b^{(i)}\\theta - y^{(i)}) * X_n^{(i)}\n",
    "\\end{matrix}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{2}{m} \\cdot (X^{(1)}_b\\theta - y^{(1)}, X_b^{(2)}\\theta - y^{(2)}, X^{(3)}_b\\theta - y^{(3)},...,X^{(m)}_b\\theta - y^{(m)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\left(\n",
    "\\begin{matrix}\n",
    "X_0^{(1)} & X_1^{(1)} & X_2^{(1)} & ... & X_n^{(1)} \\\\\n",
    "X_0^{(2)} & X_1^{(2)} & X_2^{(2)} & ... & X_n^{(2)} \\\\\n",
    "X_0^{(3)} & X_1^{(3)} & X_2^{(3)} & ... & X_n^{(3)} \\\\\n",
    "... & ... & ... & ... & ... \\\\\n",
    "X_0^{(m)} & X_1^{(m)} & X_2^{(m)} & ... & X_n^{(m)} \\\\\n",
    "\\end{matrix}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 * m 的向量，下面是m * (n + 1)的矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以损失函数现在可以写成\n",
    "$$\n",
    "    \\frac{2}{m} \\cdot (X_b\\theta - y)^T \\cdot X_b\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了求得的梯度为列向量，所以再进行一次转制:\n",
    "$$\n",
    "    \\frac{2}{m}  \\cdot X_b^T \\cdot (X_b\\theta - y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "X = X[y < 50.0]\n",
    "y = y[y < 50.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playML.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, seed=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 ms, sys: 3.91 ms, total: 15.1 ms\n",
      "Wall time: 8.35 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8129794056212895"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from playML.LinearRegression import LinearRegression\n",
    "lin_reg1 = LinearRegression()\n",
    "%time lin_reg1.fit_normal(X_train, y_train)\n",
    "lin_reg1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg2 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learning/lib/python3.6/site-packages/numpy/core/fromnumeric.py:90: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/Users/haven/Repository/Python/learning/06-Gradient-Descent/05-Vectorize-Gradient-Descent/playML/LinearRegression.py:32: RuntimeWarning: overflow encountered in square\n",
      "  return np.sum((y - X_b.dot(theta)) ** 2) / len(y)\n",
      "/Users/haven/Repository/Python/learning/06-Gradient-Descent/05-Vectorize-Gradient-Descent/playML/LinearRegression.py:54: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if abs(J(theta, X_b, y) - J(last_theta, X_b, y)) < epsilon:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2.fit_gd(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.42362e+01, 0.00000e+00, 1.81000e+01, 0.00000e+00, 6.93000e-01,\n",
       "        6.34300e+00, 1.00000e+02, 1.57410e+00, 2.40000e+01, 6.66000e+02,\n",
       "        2.02000e+01, 3.96900e+02, 2.03200e+01],\n",
       "       [3.67822e+00, 0.00000e+00, 1.81000e+01, 0.00000e+00, 7.70000e-01,\n",
       "        5.36200e+00, 9.62000e+01, 2.10360e+00, 2.40000e+01, 6.66000e+02,\n",
       "        2.02000e+01, 3.80790e+02, 1.01900e+01],\n",
       "       [1.04690e-01, 4.00000e+01, 6.41000e+00, 1.00000e+00, 4.47000e-01,\n",
       "        7.26700e+00, 4.90000e+01, 4.78720e+00, 4.00000e+00, 2.54000e+02,\n",
       "        1.76000e+01, 3.89250e+02, 6.05000e+00],\n",
       "       [1.15172e+00, 0.00000e+00, 8.14000e+00, 0.00000e+00, 5.38000e-01,\n",
       "        5.70100e+00, 9.50000e+01, 3.78720e+00, 4.00000e+00, 3.07000e+02,\n",
       "        2.10000e+01, 3.58770e+02, 1.83500e+01],\n",
       "       [6.58800e-02, 0.00000e+00, 2.46000e+00, 0.00000e+00, 4.88000e-01,\n",
       "        7.76500e+00, 8.33000e+01, 2.74100e+00, 3.00000e+00, 1.93000e+02,\n",
       "        1.78000e+01, 3.95560e+02, 7.56000e+00],\n",
       "       [2.49800e-02, 0.00000e+00, 1.89000e+00, 0.00000e+00, 5.18000e-01,\n",
       "        6.54000e+00, 5.97000e+01, 6.26690e+00, 1.00000e+00, 4.22000e+02,\n",
       "        1.59000e+01, 3.89960e+02, 8.65000e+00],\n",
       "       [7.75223e+00, 0.00000e+00, 1.81000e+01, 0.00000e+00, 7.13000e-01,\n",
       "        6.30100e+00, 8.37000e+01, 2.78310e+00, 2.40000e+01, 6.66000e+02,\n",
       "        2.02000e+01, 2.72210e+02, 1.62300e+01],\n",
       "       [9.88430e-01, 0.00000e+00, 8.14000e+00, 0.00000e+00, 5.38000e-01,\n",
       "        5.81300e+00, 1.00000e+02, 4.09520e+00, 4.00000e+00, 3.07000e+02,\n",
       "        2.10000e+01, 3.94540e+02, 1.98800e+01],\n",
       "       [1.14320e-01, 0.00000e+00, 8.56000e+00, 0.00000e+00, 5.20000e-01,\n",
       "        6.78100e+00, 7.13000e+01, 2.85610e+00, 5.00000e+00, 3.84000e+02,\n",
       "        2.09000e+01, 3.95580e+02, 7.67000e+00],\n",
       "       [5.69175e+00, 0.00000e+00, 1.81000e+01, 0.00000e+00, 5.83000e-01,\n",
       "        6.11400e+00, 7.98000e+01, 3.54590e+00, 2.40000e+01, 6.66000e+02,\n",
       "        2.02000e+01, 3.92680e+02, 1.49800e+01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2.fit_gd(X_train, y_train, eta=0.000001) # eta过大会导致overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2758681872447726"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2.score(X_test, y_test) # 可能没有达到最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 12s, sys: 265 ms, total: 2min 12s\n",
      "Wall time: 33.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time lin_reg2.fit_gd(X_train, y_train, eta=0.000001, n_iters=1e6) # eta过小时要增加迭代次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7542932581943915"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2.score(X_test, y_test) # 依然效果一般"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用梯度下降法前，最好将数据归一化；尤其是在数据不在同一级别上时"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对数据进行归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardScaler = StandardScaler()\n",
    "standardScaler.fit(X_train) # 使用StandardScaler进行归一化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_standard = standardScaler.transform(X_train) # 获得归一化处理后的X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg3 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 781 ms, sys: 7.16 ms, total: 788 ms\n",
      "Wall time: 201 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time lin_reg3.fit_gd(X_train_standard, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_standard = standardScaler.transform(X_test) # 对test也要进行归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8129873310487505"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg3.score(X_test_standard, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度下降法的优势"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1000\n",
    "n = 5000\n",
    "\n",
    "big_X = np.random.normal(size=(m, n))\n",
    "\n",
    "true_theta = np.random.uniform(0.0, 100.0, size=n+1) # n+1维的向量\n",
    "\n",
    "big_y = big_X.dot(true_theta[1:]) + true_theta[0] + np.random.normal(0., 10., size=m) # 生成虚拟数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 s, sys: 488 ms, total: 13.5 s\n",
      "Wall time: 3.54 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_reg1 = LinearRegression()\n",
    "%time big_reg1.fit_normal(big_X, big_y) # 正规化方程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.53 s, sys: 41.7 ms, total: 6.57 s\n",
      "Wall time: 1.71 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_reg2 = LinearRegression()\n",
    "%time big_reg2.fit_gd(big_X, big_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 梯度下降法更快"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
