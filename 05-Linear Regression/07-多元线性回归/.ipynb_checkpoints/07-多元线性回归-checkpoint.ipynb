{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多元线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\hat{y}^{(i)} = \\theta_0 + \\theta_1X_1^{(i)} + \\theta_2X_2^{(i)} + \\theta_3X_3^{(i)} + ...+\\theta_nX_n^{(i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于简单线性回归，目标：使\n",
    "$$\n",
    "    \\sum_{i=1}^{m}(y^{(i)} - \\hat{y}^{(i)})^2\n",
    "$$\n",
    "尽可能小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以，多元线性回归的目标就是: 找到$\\theta_0, \\theta_1, \\theta_2,...\\theta_n$，使得$\\sum_{i=1}^{m}(y^{(i)} - \\hat{y}^{(i)})^2$尽可能小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将要学习的元素整理成一个列向量\n",
    "$$\n",
    "    \\theta = (\\theta_0, \\theta_1, \\theta_2,...\\theta_n)^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再整理使$\\theta_0$也乘上一个$X$的分量\n",
    "$$\n",
    "    \\hat{y}^{(i)} = \\theta_0X_0^{(i)} + \\theta_1X_1^{(i)} + \\theta_2X_2^{(i)} + \\theta_3X_3^{(i)} + ...+\\theta_nX_n^{(i)}(X_0 \\equiv 1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    X^{(i)} = (X_0^{(i)}, X_1^{(i)}, X_2^{(i)},...,X_n^{(i)})(行向量)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    y^{(i)} = X^{(i)}\\cdot\\theta\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在原先的矩阵前多一列1，得矩阵$X_b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\theta=\n",
    "\\left(\n",
    "\\begin{matrix}\n",
    "\\theta_0\\\\\n",
    "\\theta_1\\\\\n",
    "\\theta_2\\\\\n",
    "...\\\\\n",
    "\\theta_n\n",
    "\\end{matrix}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最终:\n",
    "$$\n",
    "    \\hat{y} = X_b \\cdot \\theta\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目标: 使$\\sum_{i=1}^{m}(y^{(i)} - \\hat{y}^{(i)})^2$尽可能小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "即：使\n",
    "\n",
    "$$\n",
    "    (y - X_b \\cdot \\theta)^T(y - X_b \\cdot \\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尽可能小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推导结果：\n",
    "$$\n",
    "    \\theta = (X_b^TX_b)^{-1}X_b^Ty\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个式子也被称为多元线性回归的正规方程解(Normal Equation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但也存在**问题**: 时间复杂度高($O(n^3)$, 优化$O(n^{2.4})$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优点：不需要对数据进行归一化处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta$中，$\\theta_0$为截距(intercept)，$\\theta_1...\\theta_n$为系数(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\theta=\n",
    "\\left(\n",
    "\\begin{matrix}\n",
    "\\theta_0\\\\\n",
    "\\theta_1\\\\\n",
    "\\theta_2\\\\\n",
    "...\\\\\n",
    "\\theta_n\n",
    "\\end{matrix}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
